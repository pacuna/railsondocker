# Development

During this chapter we are going to create a new Rails application from scratch
using the latest version. We are going to build an api-only application so we
can test it easily and also because the idea of using containers to deploy applications
makes more sense when you have small applications. That's because in this kind of
architecture, you'll be pulling and pushing images to a Docker registry all the time, and
it's better to have lightweight images if we want to have faster deploys.

If you are an active member of the development community you probably have noticed
that the concept of services is taking more and more importance for web applications.
That's why we are going to be focused on these types of applications and an API
is a good representation of a small service that can be successfully deployed
using containers.

## Creating the application

Let's create a new [api-only](http://edgeguides.rubyonrails.org/api_app.html)
Rails application using [PostgreSQL](https://www.postgresql.org/)
as our database. This API will be in charge of managing articles with a small
set of fields. We just want something we can play with.
Since this book is based on containers, I'm should you a trick to create
a new Rails application without having any dependencies but Docker installed
on your machine. 

We are going to use the official [Rails image](https://hub.docker.com/_/rails/)
from Dockerhub to create this new application. We are going to run a container
using that image and pass an entrypoint with the `rails new` command along with some options.

Run the following command in your projects or code folder:

    $ docker run -it --rm --user "$(id -u):$(id -g)" -v "$PWD":/usr/src/app -w /usr/src/app \
    rails rails new --skip-bundle --api --database postgresql webapp

This command will create a rails app named `webapp` in our current directory.

As you can see, we are passing the `--api` flag so Rails generates an api-only
application, and also the `--database` flag so the drivers for our database
are pre-configured. The `--skip-bundle` flag is going to tell rails to not run
`bundle install`. This is necessary because some gems like `pg` for the PostgreSQL
database sometimes required that we have some dependencies installed on our machine. So here we are going
to get a new Rails app but without its dependencies. That's ok, since we want to install
the dependencies in the actual container instead our machine.

Now we need an extra step. Since we create the application without running `bundle install`,
we don't have a Gemfile.lock holding the gem versioning. Our scheme requires we have
that file. We are going to use another trick to generate the file. This time we are going to mount
the recently created application in a ruby container and run bundle install from within the container.
The command will generate a Gemfile.lock file which will be also in our directory product of the
volume mount:

    $ cd webapp
    $ docker run --rm -v "$PWD":/usr/src/app -w /usr/src/app ruby:2.3 bundle install

And that's it. Now we have our Gemfile and Gemfile.lock and application is ready to be
dockerized.

Sadly since we don't have any dependencies installed on our machine, we cannot test this application in the
typical way by running `rails s`. Remember we don't even have Rails installed. So we'll
have to wait a little bit until we can run the `webapp` within a Docker container.

## Dockerizing the application

With all the Docker images available these days, it's pretty easy to dockerize
an application. In our case we only going to need something for the Rails app
and something for PostgreSQL. For rails you have practically the same
options you have when you don't use containers for deployments (Unicorn, Puma, Passenger, etc). And for PostgreSQL
we can use the official image from DockerHub.

For Ruby/Rails I strongly recommend you to use the [phusion passenger-docker](https://github.com/phusion/passenger-docker) image.
It has a lot of features and a very nice documentation.
You can have a solid production application server out of the box with that image, so we will stick
with that during this book. Keep in mind that if you choose another application server
like `unicorn` or `puma`, the setup is going to be quite different.

The Docker and Docker Compose versions I'll be using for this section are:

- Docker Version 1.12.1
- Docker Compose version 1.8.0

First we are going to create a development environment by using Docker Compose.

This environment is going to be just for development, since for production we want to use
a more robust tool with cluster management like Kubernetes or ECS.

Even though we don't want to use Docker Compose for production, it's a very realistic
scenario to see our our containers are interacting with each other and if you have a working
environment with Docker Compose, it's going to be much easily to have a working production environment. That's
the beauty of containers.

The application needs to be build using the phusion passenger-docker as the base image. So
we need a Dockerfile. This Dockerfile is also going to add the application source code
along with other configuration files to the container.

The typical configuration that you need for this image, are the nginx virtual host
for your application and a file for declaring the environmental variables
you may need to pass to the application. First, let's create a file for holding
the virtual host configuration. You can create all of these files in the root of the `webapp`
application:

    $ touch webapp.conf

And add the following to that file:

    server {
        listen 80;
        server_name _;
        root /home/app/webapp/public;

        passenger_enabled on;
        passenger_user app;

        passenger_ruby /usr/bin/ruby2.3;
    }

As you can see we have a very simple virtual host configuration for Nginx and passenger. This
file will be added to the available hosts of the server during the container
build.

Now let's add a file for the environmental variables. We'll put some just
so we know how to declare them if we want to use them later:

    $ touch rails-env.conf

And add the following:

    env SECRET_KEY_BASE;
    env DATABASE_URL;
    env DATABASE_PASSWORD;

We won't be using those variables during development so don't worry about them
for now. You just need to know that every environmental variable that you need
in your application should be declared here so they are preserved and forwarded to your
web application.

Now we can create the Dockerfile that's going to add those files along the entire application.

I've added comments for every instruction so you can know what's happening
on every step during the build. If you still have doubts about some instructions,
just go to the [official repository](https://github.com/phusion/passenger-docker)
of the image and take a look at the documentation, it's really good.

    $ touch Dockerfile

And the content:

    FROM phusion/passenger-ruby23:0.9.19

    # Set correct environment variables.
    ENV HOME /root

    # Use baseimage-docker's init process.
    CMD ["/sbin/my_init"]

    # Additional packages: we are adding the netcat package so we can
    # make pings to the database service
    RUN apt-get update && apt-get install -y -o Dpkg::Options::="--force-confold" netcat

    # Enable Nginx and Passenger
    RUN rm -f /etc/service/nginx/down

    # Add virtual host entry for the application. Make sure
    # the file is in the correct path
    RUN rm /etc/nginx/sites-enabled/default
    ADD webapp.conf /etc/nginx/sites-enabled/webapp.conf

    # In case we need some environmental variables in Nginx. Make sure
    # the file is in the correct path
    ADD rails-env.conf /etc/nginx/main.d/rails-env.conf

    # Install gems: it's better to build an independent layer for the gems
    # so they are cached during builds unless Gemfile changes
    WORKDIR /tmp
    ADD Gemfile /tmp/
    ADD Gemfile.lock /tmp/
    RUN bundle install

    # Copy application into the container and use right permissions: passenger
    # uses the app user for running the application
    RUN mkdir /home/app/webapp
    COPY . /home/app/webapp
    RUN usermod -u 1000 app
    RUN chown -R app:app /home/app/webapp
    WORKDIR /home/app/webapp


    # Clean up APT when done.
    RUN apt-get clean && rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/*

    EXPOSE 80

This Dockerfile should do the trick for our Rails application. It might seem a little
bit complicated at first, but trust me, you'll get used to it after building a
couple of Rails services.

The cool thing about this setup, is that you'll be using
the same server for development and production, so you'll have a lot less work to do
once you ship the application to production. This image in particular uses the `PASSENGER_APP_ENV`
variable for setting the environment. So for example in Rails, that variable
also controls the `RAILS_ENV` variable.

Now that we have the Dockerfile for building our application, we need a Docker
Compose file so we can run the database and then test these containers to see
if everything works fine.

We'll need to declare three services in our Docker Compose file. One for our web application,
one for the PostgreSQL database, and one setup container for running initialization commands.
This setup container will be run before the actual application, and it's
going to migrate our database.

> It's a good practice to run tasks in separate containers. In a production scenario
> you may want to run several containers for your web application, and if you run initialization
> commands in that same container (such as migrations), you'll have collisions, since
> all the container will be running those commands before start.

### Setup Container

Like I mentioned before, we need a mechanism to run initialization commands.
In a Rails application, these are typically `rails db:create`, `rails db:migrate`
and `rails assets:precompile`. We can't run those commands in the same container
that we're running our web application. That would work fine if you're deploying
only one container, but suppose you want to scale your application and you want to run
ten containers, then every one of those containers will try to execute
those commands during startup time and things can get ugly. With that said, it's
always better to separate concerns and to use an independent container for running
tasks and then just remove it once it finishes.

This setup container has to use the same Dockerfile that we just created
since it needs access to the whole application environment. The only part we need to
overwrite it's the entrypoint.

Right now we don't have an entrypoint for our container since
we want to use the one the same image is providing for us. But since this
setup container doesn't need to run as a web application, we can just
overwrite it with our own initialization commands. Let's create this new entrypoint script
in our root path:

    $ touch setup.sh

And add the following:

    #!/bin/sh

    echo "Waiting PostgreSQL to start on 5432..."

    while ! nc -z postgres 5432; do
      sleep 0.1
    done

    echo "PostgreSQL started"

    bin/rails db:migrate

The whole purpose of this script is to run the possible new
migrations our application may have. But, what if the database is not yet
available for the command? That would generate an error and the whole
run would crash. That's why we use a while expressions that's going to loop
until the connection is alive.
We are using the `netcat` package for this and also we're assuming
that the PostgreSQL service endpoint will be reachable by using the `postgres`
alias.
Finally, when the connection is alive, we can run the latests migrations.

Let's also add the proper execution permissions to this file:

    $ chmod +x setup.sh

This type of scripts are very usual when you need to orchestrate different services
that are constantly being shut down and turned on. So you better get use to get your
hands dirty with some bash when you run containers.

Let's create the `docker-compose.yml` file in our root path and add the service:

    $ touch docker-compose.yml

And the first service:

    version: '2'
    services:
      webapp_setup:
        build: .
        depends_on:
          - postgres
        environment:
          - PASSENGER_APP_ENV=development
        entrypoint: ./setup.sh

This service will use the Dockerfile we already have for the build. It has
a dependency on a service we haven't declared yet and which name will be `postgres`.

We are also passing an environmental variable for the Rails environment. This is one
of the ways of setting the `RAILS_ENV` variable for this image and it's described
in the documentation.

Finally, we are overwriting the entrypoint with the previous bash script.
Since this script doesn't do anything after the migration, the container will be exited
when it finishes, which is want we want.

### Web Application Container

This service will be similar to the setup service. The differences are:

- We need to declare a dependency on the setup container so it always runs after it
- We need to map the port 80 of the container to our host if we want to access our application via HTTP
- We don't need to override the entrypoint

We can express all of that with:

    webapp:
      container_name: webapp
      build: .
      depends_on:
        - postgres
        - webapp_setup
      environment:
        - PASSENGER_APP_ENV=development
      ports:
        - "80:80"

As you can see in this service, we are not touching the entrypoint. The default one
provided by the base image will be executed and the application will be launched as a web
application.
Those two dependencies will assure us that this container will be started after
the database is ready for accepting connections and the setup container has been
executed.

### Database Container

The PostgreSQL service will be very simple. We need to pull the `postgres:9.5.3` image
from DockerHub and set up a couple of environmental variables like the user,
password and database name:

    postgres:
      image: postgres:9.5.3
      environment:
        - POSTGRES_PASSWORD=mysecretpassword
        - POSTGRES_USER=webapp
        - POSTGRES_DB=webapp_development

In this case our user will be `webapp` and we want to use the default database
name that Rails set up for us in the database config file.

Since the container will create this database during startup, we don't need to run `rails db:create`
in our application initialization script.

Keep in mind that for a daily development workflow, you **want** to mount your source
file into the application container. That way you can see your changes immediately
inside of the container. You can accomplish this with just one line of code:

    volumes:
      - .:/home/app/webapp

That's going to mount your local source code to the folder where the application
lives inside of the container.

You also may want to create a data-only container for holding our database data.
This way, is we destroy the postgres container for some reason, our development
data would still be there. This patter is useful for all other kind of stateful applications, like
search engines, cache stores, etc.

We can add this data-only container with:

    postgres_data:
        image: postgres:9.5.3
        volumes:
          - /var/lib/postgresql/data
        command: /bin/true

And use the volume from the postgres service by adding:

    volumes_from:
          - postgres_data

To the service.

The final `docker-compose.yml` file should look like this:

    version: '2'
    services:
      webapp_setup:
        build: .
        depends_on:
          - postgres
        environment:
          - PASSENGER_APP_ENV=development
        entrypoint: ./setup.sh
      webapp:
        container_name: webapp
        build: .
        depends_on:
          - postgres
          - webapp_setup
        environment:
          - PASSENGER_APP_ENV=development
        ports:
          - "80:80"
        volumes:
          - .:/home/app/webapp
      postgres:
        image: postgres:9.5.3
        environment:
          - POSTGRES_PASSWORD=mysecretpassword
          - POSTGRES_USER=webapp
          - POSTGRES_DB=webapp_development
        volumes_from:
          - postgres_data
      postgres_data:
          image: postgres:9.5.3
          volumes:
            - /var/lib/postgresql/data
          command: /bin/true

### Build and Run

Let's run a Docker Compose build first for building our web application and
setup containers:

    $ docker-compose build

Output (truncated):

    postgres_data uses an image, skipping
    postgres uses an image, skipping
    Building webapp_setup
    Step 1 : FROM phusion/passenger-ruby23:0.9.19
    0.9.19: Pulling from phusion/passenger-ruby23
    f069f1d21059: Extracting [===>] 3.146 MB/49.17 MB
    ecbeec5633cf: Download complete
    ea6f18256d63: Download complete
    54bde7b02897: Waiting
    a3ed95caeb02: Waiting
    ce9e695a6234: Waiting
    346026b9659b: Waiting
    ffaf5356e027: Waiting
    85417a8aee4f: Waiting
    ...

The first time you run this command it may take some time, since the Docker engine has
to pull the image, install the dependencies and install the gems inside the container. If you
follow the output of the build, you should all these steps.

At the end you should see something like this in the output:

        (truncated)
    Building webapp
    Step 1 : FROM phusion/passenger-ruby23:0.9.19
     ---> 6841e494987f
    Step 2 : ENV HOME /root
     ---> Using cache
     ---> e70985107acc
    Step 3 : CMD /sbin/my_init
     ---> Using cache
     ---> babd8b525225
    Step 4 : RUN apt-get update && apt-get install -y -o Dpkg::Options::="--force-confold" netcat
     ---> Using cache
     ---> 74da8c84b454
    Step 5 : RUN rm -f /etc/service/nginx/down
     ---> Using cache
     ---> 16d62000d878
    Step 6 : RUN rm /etc/nginx/sites-enabled/default
     ---> Using cache
     ---> 0b6a404fc6cc
    Step 7 : ADD webapp.conf /etc/nginx/sites-enabled/webapp.conf
     ---> Using cache
     ---> 5d1327265ff2
    Step 8 : ADD rails-env.conf /etc/nginx/main.d/rails-env.conf
     ---> Using cache
     ---> 45b636122c30
    Step 9 : WORKDIR /tmp
     ---> Using cache
     ---> 55878be0e6a5
    Step 10 : ADD Gemfile /tmp/
     ---> Using cache
     ---> ed9c23c126a3
    Step 11 : ADD Gemfile.lock /tmp/
     ---> Using cache
     ---> af7aeac5d540
    Step 12 : RUN bundle install
     ---> Using cache
     ---> 6259538ad852
    Step 13 : RUN mkdir /home/app/webapp
     ---> Using cache
     ---> eec9872fe976
    Step 14 : COPY . /home/app/webapp
     ---> Using cache
     ---> 2155626c9eb4
    Step 15 : RUN usermod -u 1000 app
     ---> Using cache
     ---> 4f0275216dce
    Step 16 : RUN chown -R app:app /home/app/webapp
     ---> Using cache
     ---> ee6949c8496c
    Step 17 : WORKDIR /home/app/webapp
     ---> Using cache
     ---> 40d5c1499bc8
    Step 18 : RUN apt-get clean && rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/*
     ---> Using cache
     ---> 0c39cab889a8
    Step 19 : EXPOSE 80
     ---> Using cache
     ---> 4d463695a9f1
    Successfully built 4d463695a9f1

That whole section is for the webapp container. As you can see, the layers
were already cached, since they're shared with the setup container, which was built first.
That's just for showing you that even though we have to build two containers, which both run `bundle install`,
the build is made virtually just once and then the layers are all cached.

Before running `docker-compose up`, which will start the whole environment, we have to
configure our database credentials. Remember we are using an alias for the postgres
host.

Open the `config/database.yml` file, and change the default section to:

    default: &default
      adapter: postgresql
      encoding: unicode
      user: webapp
      password: mysecretpassword
      host: postgres
      pool: <%= ENV.fetch("RAILS_MAX_THREADS") { 5 } %>

Now we can run the Docker Compose up command to pull the PostgreSQL image,
run the initialization script and setup the entire system:

    $ docker-compose up

Some interesting parts you can see in the output are:

    Pulling postgres (postgres:9.5.3)...
    5c90d4a2d1a8: Extracting [=================================================> ] 50.86 MB/51.35 MB
    5c90d4a2d1a8: Downloading [===========================>                       ] 28.25 MB/51.35 MB complete
    c3961b297acc: Download complete
    ...

For the PostgreSQL image pull. Also:

    webapp_setup_1   | PostgreSQL started
    postgres_1       | LOG:  incomplete startup packet
    postgres_1       | LOG:  database system was shut down at 2016-09-25 21:52:32 UTC
    postgres_1       | LOG:  MultiXact member wraparound protections are now enabled
    postgres_1       | LOG:  database system is ready to accept connections
    postgres_1       | LOG:  autovacuum launcher started
    webapp_webapp_setup_1 exited with code 0

For the setup container in action. We don't have any migrations yet, so the container
is exited with no output.

Also, if you look at the line that says:

    webapp_setup_1   | Waiting PostgreSQL to start on 5432...

You can see the setup container trying to connect to the PostgreSQL container
in order to run the migrations, but the PostgreSQL initialization wasn't ready yet.

Finally you'll see something like this:

    webapp           | [ 2016-09-25 21:52:33.0180 29/7f54586a2780 age/Wat/WatchdogMain.cpp:1291 ]: Starting Passenger watchdog...
    webapp           | [ 2016-09-25 21:52:33.0431 32/7f7e4c98f780 age/Cor/CoreMain.cpp:982 ]: Starting Passenger core...
    webapp           | [ 2016-09-25 21:52:33.0433 32/7f7e4c98f780 age/Cor/CoreMain.cpp:235 ]: Passenger core running in multi-application mode.
    webapp           | [ 2016-09-25 21:52:33.0453 32/7f7e4c98f780 age/Cor/CoreMain.cpp:732 ]: Passenger core online, PID 32
    webapp           | [ 2016-09-25 21:52:33.0665 37/7fb989671780 age/Ust/UstRouterMain.cpp:529 ]: Starting Passenger UstRouter...
    webapp           | [ 2016-09-25 21:52:33.0673 37/7fb989671780 age/Ust/UstRouterMain.cpp:342 ]: Passenger UstRouter online, PID 37

Which indicates that the passenger and Nginx processes are ready and listening.

Let's test the application via cURL. You should replace the localhost address
with whatever you're using for running Docker. In my case I'm using Docker for Mac,
so my Docker IP is localhost. Also remember not to kill the Docker Compose up process.

Open a different tab and test the root path:

    $ curl -I localhost

Output:

    HTTP/1.1 200 OK
    Content-Type: text/html; charset=utf-8
    Connection: keep-alive
    Status: 200 OK
    Cache-Control: max-age=0, private, must-revalidate
    ETag: W/"b62d4f67b7b823c017534cd9727752cd"
    X-Frame-Options: SAMEORIGIN
    X-XSS-Protection: 1; mode=block
    X-Content-Type-Options: nosniff
    X-Runtime: 0.020162
    X-Request-Id: 5df5e6c8-a441-4582-ab32-67bd6b148279
    Date: Sun, 25 Sep 2016 21:57:01 GMT
    X-Powered-By: Phusion Passenger 5.0.29
    Server: nginx/1.10.1 + Phusion Passenger 5.0.29

Great! Our application is running correctly on development environment.

## Adding a resource

We said this was going to be an API for managing articles, so let's create
a simple article resource.

For this, we can run a simple command with Docker Compose, that uses our same
webapp service but also overrides the entrypoint with whatever we want.

Open a new terminal tab in your project's root folder and let's scaffold a new resource with:

    $ docker-compose run --rm webapp bin/rails g scaffold articles title:string body:text

Output:

    Starting webapp_postgres_data_1
    Starting webapp_webapp_setup_1
    [WARNING] The model name 'articles' was recognized as a plural, using the singular 'article' instead. Override with --force-plural or setup custom inflection rules for this noun before running the generator.
          invoke  active_record
          create    db/migrate/20160925220117_create_articles.rb
          create    app/models/article.rb
          invoke    test_unit
          create      test/models/article_test.rb
          create      test/fixtures/articles.yml
          invoke  resource_route
           route    resources :articles
          invoke  scaffold_controller
          create    app/controllers/articles_controller.rb
          invoke    test_unit
          create      test/controllers/articles_controller_test.rb

That's going to create the necessary files for the scaffold, and since we have a volume
for this project, we also have those files locally. That's a workflow you have to learn
when working with containers. Locally you're only editing files, but all the tasks and executions
happen inside of the container, so you normally want to run commands with docker-compose
and add the `--rm` flag so the container is deleted after, or you may want to keep an open
connection inside of the container by using `docker exec -it webapp bash`, and run
all your commands from there.

The scaffold we just created is actually pretty cool because it detects that our application
is api-only, so it generates a controller already adapted for
JSON responses.

Let's migrate the database:

    $ docker-compose run --rm webapp bin/rails db:migrate

Output:

    Starting webapp_postgres_data_1
    Starting webapp_webapp_setup_1
    == 20160925220117 CreateArticles: migrating ===================================
    -- create_table(:articles)
       -> 0.0621s
    == 20160925220117 CreateArticles: migrated (0.0622s) ==========================

If we want to run the tests Rails created for us, we first have to create
the test database:

    $ docker-compose run --rm webapp bash -c "RAILS_ENV=test bin/rails db:create"

And the run the tests:

    $ docker-compose run --rm webapp bash -c "RAILS_ENV=test bin/rake"

Output:

    Starting webapp_postgres_data_1
    Starting webapp_webapp_setup_1
    Run options: --seed 4172

    # Running:

    .....

    Finished in 0.954391s, 5.2389 runs/s, 7.3345 assertions/s.

    5 runs, 7 assertions, 0 failures, 0 errors, 0 skips

Let's test the endpoint for creating articles. We are going to use cURL
for interacting with our API.
Run the following command, but first, make sure the `docker-compose up` command
is still running:

    $ curl -H "Content-Type: application/json" -X POST -d '{"title":"my first article","body":"Lorem ipsum dolor sit amet, consectetur adipiscing elit..."}' http://localhost/articles

Output:

    {"id":1,"title":"my first article","body":"Lorem ipsum dolor sit amet, consectetur adipiscing elit...","created_at":"2016-09-25T22:10:19.407Z","updated_at":"2016-09-25T22:10:19.407Z"}%

That means the article was indeed created in our database. Just in case you don't
believe me let's run a Rails console and inspect a little bit:

    $ docker-compose exec webapp bin/rails c

    Loading development environment (Rails 5.0.0.1)
    2.3.1 :001 > Article.first
      Article Load (0.6ms)  SELECT  "articles".* FROM "articles" ORDER BY "articles"."id" ASC LIMIT $1  [["LIMIT", 1]]
     => #<Article id: 1, title: "my first article", body: "Lorem ipsum dolor sit amet, consectetur adipiscing...", created_at: "2016-09-25 22:10:19", updated_at: "2016-09-25 22:10:19">

We can use the `exec` command to open extra processes inside of our containers. In this case
I'm running the `rails c` command which will run the console in that container and keep
the interactive mode so we can try some commands. As you can see, we have the record
we just created via cURL, so we are pretty sure our setup is working properly.

> Tip: Use `docker-compose up -d` to run your environment in detached mode so you
> can keep using that same terminal window to interact with your container.

## Log issues

A very important and complex topic with container is Logging.
Docker logs work by inspecting the `STDOUT` connection. That's a problem for
a Rails application, since all the logging is piped to a file in the log's directory.
Luckily for us, we just need to change one line in our source code to send the logs
to the `STDOUT` connection.

Open the 'config/application.rb` file and add the following configuration:

    config.logger = Logger.new(STDOUT)

And that's it. Now for example, you should be able to see the application logs
with the `docker-compose logs` tool.
To apply this change, let's stop the `docker-compose up` command with `C-c` and
rebuild the project:

    $ # C-c

Output:

    Killing webapp ... done
    Killing webapp_postgres_1 ... done

    $ docker-compose build

We are going to run `docker-compose up` in detached mode and follow the logs
with the logs command:

    $ docker-compose up -d && docker-compose logs -f

Now, open a new tab and again run a command using curl:

    $ curl -I localhost

If you see the logs in the other window, you should see the Rails logger
in action:

    webapp           | App 443 stdout: I, [2016-09-25T22:23:21.861253 #443]  INFO -- : Started HEAD "/" for 172.18.0.1 at 2016-09-25 22:23:21 +0000
    webapp           | App 443 stdout: D, [2016-09-25T22:23:22.110304 #443] DEBUG -- :   ActiveRecord::SchemaMigration Load (0.9ms)  SELECT "schema_migrations".* FROM "schema_migrations"
    webapp           | App 443 stdout: I, [2016-09-25T22:23:22.157587 #443]  INFO -- : Processing by Rails::WelcomeController#index as */*
    webapp           | App 443 stdout: I, [2016-09-25T22:23:22.157720 #443]  INFO -- :   Parameters: {"internal"=>true}
    webapp           | App 443 stdout: I, [2016-09-25T22:23:22.178806 #443]  INFO -- :   Rendering /usr/local/rvm/gems/ruby-2.3.1/gems/railties-5.0.0.1/lib/rails/templates/rails/welcome/index.html.erb
    webapp           | App 443 stdout: I, [2016-09-25T22:23:22.186551 #443]  INFO -- :   Rendered /usr/local/rvm/gems/ruby-2.3.1/gems/railties-5.0.0.1/lib/rails/templates/rails/welcome/index.html.erb (7.5ms)
    webapp           | App 443 stdout: I, [2016-09-25T22:23:22.187048 #443]  INFO -- : Completed 200 OK in 29ms (Views: 25.2ms | ActiveRecord: 0.0ms)
    webapp           | App 443 stdout:
    webapp           | App 443 stdout:

Having your logs propertly configured is important for production tools like
Kubernetes and ECS, where inspecting things can be more difficult than on development.
You don't want to go inside of your production containers and start to follow logs, mainly
because you'll first would have to find the right node that's running that container, and that
ruins the whole point of clustered applications.

## Pushing the app to DockerHub

In order to be able to run our web application with Kubernetes or ECS, we need to push
our image to some registry. Let's use a public repository from DockerHub.

First, make sure you are logged in with your Docker account by running:

    $ docker login

That's going to ask you for your DockerHub credentials.

Now go to `https://hub.docker.com/` and create a new public repository and name it `webapp`.

A change that we want to make first, it's to create a dockerignore file. 
I said before that we want to keep our images as lightest as possible, so the same way we do
did our Git Repositories, there are some files we can ommit.
Let's create .dockerignore file and add the files we don't want to copy into our
images:

    $ touch .dockerignore

And add:

    # Ignore bundler config.
    /.bundle

    # Ignore all logfiles and tempfiles.
    /log/*
    /tmp/*
    !/log/.keep
    !/tmp/.keep

    # Ignore Byebug command history file.
    .byebug_history

We are basically copying what's inside of the .gitignore file for a standard Rails app.

Now, let's build an initial version of our application. A practice that I've found to be
good and clear, is to tag the images accord to your latest Git commit hash. Of course
we want to use the short version of the commit.

First, we have to tell git that this is a repository, so in the root of your
application run:

    $ git init
    $ git add -A
    $ git commit -m 'Add dockerized Rails app'

Now we can save the short version of the latest commit hash with:

    LC=$(git rev-parse --short HEAD)

That's very convenient for tagging our image using that variable instead of copying
the string.

Let's build our first image using that tag. Replace my username with your DockerHub username
and also the repository name in case you didn't use `webapp`:

    $ docker build -t pacuna/webapp:${LC} .

And now push it to the remote repository:

    $ docker push pacuna/webapp:${LC}

Output (truncated):

    The push refers to a repository [docker.io/pacuna/webapp]
    70e47e879cb0: Pushed
    2f00f00b770f: Pushed
    6a061828948b: Pushed
    87db749cfa82: Pushed
    f7feb319b319: Pushed
    0945e5099009: Pushing [==>                                                ] 4.929 MB/105.2 MB
    90f2b6e5ebff: Pushing [==================================================>] 5.632 kB
    20138267dbc3: Pushed
    094f4202572b: Pushing [==================================================>] 3.584 kB
    f9cdde53d648: Pushing [==================================================>] 3.584 kB
    fa4354a3646d: Waiting
    662bc11192df: Waiting
    ...

And that's it! Now our image is ready for being deployed with the orquestration
framework we want to use.
