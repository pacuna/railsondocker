# Development

During this chapter we are going to create a new Rails application from scratch
using the latest version. We are going to build an api-only application so we
can test it easily and also because the idea of using containers to deploy applications
makes more sense when you have small applications. That's because in this kind of
architecture, you'll be pulling and pushing images to a Docker registry all the time, and
it's better to have lightweight images if we want to have faster deploys.

If you are an active member of the development community you probably have noticed
that the concept of services is taking more and more importance for web applications.
That's why we are going to be focused on these types of applications and an API
is a good representation of a small service that can be successfully deployed
using containers.

## Creating the application

Let's create a new [api-only](http://edgeguides.rubyonrails.org/api_app.html)
Rails application using [PostgreSQL](https://www.postgresql.org/)
as our database. This API will be in charge of managing articles with a small
set of fields. We just want something we can play with.
Since this book is based on containers, I'm should you a trick to create
a new Rails application without having any dependencies but Docker installed
on your machine. 

We are going to use the official [Rails image](https://hub.docker.com/_/rails/)
from Dockerhub to create this new application. We are going to run a container
using that image and pass an entrypoint with the `rails new` command along with some options.

Run the following command in your projects or code folder:

    $ docker run -it --rm --user "$(id -u):$(id -g)" -v "$PWD":/usr/src/app -w /usr/src/app \
    rails rails new --skip-bundle --api --database postgresql webapp

This command will create a rails app named `webapp` in our current directory.

As you can see, we are passing the `--api` flag so Rails generates an api-only
application, and also the `--database` flag so the drivers for our database
are pre-configured. The `--skip-bundle` flag is going to tell rails to not run
`bundle install`. This is necessary because some gems like `pg` for the PostgreSQL
database sometimes required that we have some dependencies installed on our machine. So here we are going
to get a new Rails app but without its dependencies. That's ok, since we want to install
the dependencies in the actual container instead our machine.

Now we need an extra step. Since we create the application without running `bundle install`,
we don't have a Gemfile.lock holding the gem versioning. Our scheme requires we have
that file. We are going to use another trick to generate the file. This time we are going to mount
the recently created application in a ruby container and run bundle install from within the container.
The command will generate a Gemfile.lock file which will be also in our directory product of the
volume mount:

    $ cd webapp
    $ docker run --rm -v "$PWD":/usr/src/app -w /usr/src/app ruby:2.3 bundle install

And that's it. Now we have our Gemfile and Gemfile.lock and application is ready to be
dockerized.

Sadly since we don't have any dependencies installed on our machine, we cannot test this application in the
typical way by running `rails s`. Remember we don't even have Rails installed. So we'll
have to wait a little bit until we can run the `webapp` within a Docker container.

## Dockerizing the application

With all the Docker images available these days, it's pretty easy to dockerize
an application. In our case we only going to need something for the Rails app
and something for PostgreSQL. For rails you have practically the same
options you have when you don't use containers for deployments (Unicorn, Puma, Passenger, etc). And for PostgreSQL
we can use the official image from DockerHub.

For Ruby/Rails I strongly recommend you to use the [phusion passenger-docker](https://github.com/phusion/passenger-docker) image.
It has a lot of features and a very nice documentation.
You can have a solid production application server out of the box with that image, so we will stick
with that during this book. Keep in mind that if you choose another application server
like `unicorn` or `puma`, the setup is going to be quite different.

The Docker and Docker Compose versions I'll be using for this section are:

- Docker Version 1.12.1
- Docker Compose version 1.8.0

First we are going to create a development environment by using Docker Compose.

This environment is going to be just for development, since for production we want to use
a more robust tool with cluster management like Kubernetes or ECS.

Even though we don't want to use Docker Compose for production, it's a very realistic
scenario to see our our containers are interacting with each other and if you have a working
environment with Docker Compose, it's going to be much easily to have a working production environment. That's
the beauty of containers.

The application needs to be build using the phusion passenger-docker as the base image. So
we need a Dockerfile. This Dockerfile is also going to add the application source code
along with other configuration files to the container.

The typical configuration that you need for this image, are the nginx virtual host
for your application and a file for declaring the environmental variables
you may need to pass to the application. First, let's create a file for holding
the virtual host configuration. You can create all of these files in the root of the `webapp`
application:

    $ touch webapp.conf

And add the following to that file:

    server {
        listen 80;
        server_name _;
        root /home/app/webapp/public;

        passenger_enabled on;
        passenger_user app;

        passenger_ruby /usr/bin/ruby2.3;
    }

As you can see we have a very simple virtual host configuration for Nginx and passenger. This
file will be added to the available hosts of the server during the container
build.

Now let's add a file for the environmental variables. We'll put some just
so we know how to declare them if we want to use them later:

    $ touch rails-env.conf

And add the following:

    env SECRET_KEY_BASE;
    env DATABASE_URL;
    env DATABASE_PASSWORD;

We won't be using those variables during development so don't worry about them
for now. You just need to know that every environmental variable that you need
in your application should be declared here so they are preserved and forwarded to your
web application.

Now we can create the Dockerfile that's going to add those files along the entire application.

I've added comments for every instruction so you can know what's happening
on every step during the build. If you still have doubts about some instructions,
just go to the [official repository](https://github.com/phusion/passenger-docker)
of the image and take a look at the documentation, it's really good.

    $ touch Dockerfile

And the content:

    FROM phusion/passenger-ruby23:0.9.19

    # Set correct environment variables.
    ENV HOME /root

    # Use baseimage-docker's init process.
    CMD ["/sbin/my_init"]

    # Additional packages: we are adding the netcat package so we can
    # make pings to the database service
    RUN apt-get update && apt-get install -y -o Dpkg::Options::="--force-confold" netcat

    # Enable Nginx and Passenger
    RUN rm -f /etc/service/nginx/down

    # Add virtual host entry for the application. Make sure
    # the file is in the correct path
    RUN rm /etc/nginx/sites-enabled/default
    ADD webapp.conf /etc/nginx/sites-enabled/webapp.conf

    # In case we need some environmental variables in Nginx. Make sure
    # the file is in the correct path
    ADD rails-env.conf /etc/nginx/main.d/rails-env.conf

    # Install gems: it's better to build an independent layer for the gems
    # so they are cached during builds unless Gemfile changes
    WORKDIR /tmp
    ADD Gemfile /tmp/
    ADD Gemfile.lock /tmp/
    RUN bundle install

    # Copy application into the container and use right permissions: passenger
    # uses the app user for running the application
    RUN mkdir /home/app/webapp
    COPY . /home/app/webapp
    RUN usermod -u 1000 app
    RUN chown -R app:app /home/app/webapp
    WORKDIR /home/app/webapp


    # Clean up APT when done.
    RUN apt-get clean && rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/*

    EXPOSE 80

This Dockerfile should do the trick for our Rails application. It might seem a little
bit complicated at first, but trust me, you'll get used to it after building a
couple of Rails services.

The cool thing about this setup, is that you'll be using
the same server for development and production, so you'll have a lot less work to do
once you ship the application to production. This image in particular uses the `PASSENGER_APP_ENV`
variable for setting the environment. So for example in Rails, that variable
also controls the `RAILS_ENV` variable.

Now that we have the Dockerfile for building our application, we need a Docker
Compose file so we can run the database and then test these containers to see
if everything works fine.

We'll need to declare three services in our Docker Compose file. One for our web application,
one for the PostgreSQL database, and one setup container for running initialization commands.
This setup container will be run before the actual application, and it's
going to migrate our database.

> It's a good practice to run tasks in separate containers. In a production scenario
> you may want to run several containers for your web application, and if you run initialization
> commands in that same container (such as migrations), you'll have collisions, since
> all the container will be running those commands before start.

### Setup Container

Like I mentioned before, we need a mechanism to run initialization commands.
In a Rails application, these are typically `rails db:create`, `rails db:migrate`
and `rails assets:precompile`. We can't run those commands in the same container
that we're running our web application. That would work fine if you're deploying
only one container, but suppose you want to scale your application and you want to run
ten containers, then every one of those containers will try to execute
those commands during startup time and things can get ugly. With that said, it's
always better to separate concerns and to use an independent container for running
tasks and then just remove it once it finishes.

This setup container has to use the same Dockerfile that we just created
since it needs access to the whole application environment. The only part we need to
overwrite it's the entrypoint.

Right now we don't have an entrypoint for our container since
we want to use the one the same image is providing for us. But since this
setup container doesn't need to run as a web application, we can just
overwrite it with our own initialization commands. Let's create this new entrypoint script
in our root path:

    $ touch setup.sh

And add the following:

    #!/bin/sh

    echo "Waiting PostgreSQL to start on 5432..."

    while ! nc -z postgres 5432; do
      sleep 0.1
    done

    echo "PostgreSQL started"

    rails db:migrate

The whole purpose of this script is to run the possible new
migrations our application may have. But, what if the database is not yet
available for the command? That would generate an error and the whole
run would crash. That's why we use a while expressions that's going to loop
until the connection is alive.
We are using the `netcat` package for this and also we're assuming
that the PostgreSQL service endpoint will be reachable by using the `postgres`
alias.
Finally, when the connection is alive, we can run the latests migrations.

Let's also add the proper execution permissions to this file:

    $ chmod +x setup.sh

This type of scripts are very usual when you need to orchestrate different services
that are constantly being shut down and turned on. So you better get use to get your
hands dirty with some bash when you run containers.

Let's create the `docker-compose.yml` file in our root path and add the service:

    $ touch docker-compose.yml

And the first service:

    version: '2'
    services:
      webapp_setup:
        build: .
        depends_on:
          - postgres
        environment:
          - PASSENGER_APP_ENV=development
        entrypoint: ./setup.sh

This service will use the Dockerfile we already have for the build. It has
a dependency on a service we haven't declared yet and which name will be `postgres`.

We are also passing an environmental variable for the Rails environment. This is one
of the ways of setting the `RAILS_ENV` variable for this image and it's described
in the documentation.

Finally, we are overwriting the entrypoint with the previous bash script.
Since this script doesn't do anything after the migration, the container will be exited
when it finishes, which is want we want.

### Web Application Container

This service will be similar to the setup service. The differences are:

- We need to declare a dependency on the setup container so it always runs after it
- We need to map the port 80 of the container to our host if we want to access our application via HTTP

We can express all of that with:

    webapp:
      build: .
      depends_on:
        - postgres
        - webapp_setup
      environment:
        - PASSENGER_APP_ENV=development
      ports:
        - "80:80"

As you can see in this service, we are not touching the entrypoint. The default one
provided by the base image will be executed and the application will be launched as a web
application.

### Database Container

The PostgreSQL service will be very simple. We need to pull the `postgres:9.5.3` image
from the DockerHub and set up a couple of environmental variables like the user,
password and database name:

    postgres:
      image: postgres:9.5.3
      environment:
        - POSTGRES_PASSWORD=mysecretpassword
        - POSTGRES_USER=articles

If we don't declare the database name, the container will create one with the same
user name. In this case our user and database will be `articles`.
Since the container will create this database during startup, we don't need to run `rake db:create`
in our application initialization script.

You can get fancy and add data volumes for persisting the database data and for
mounting your source into the web application container, but since this book
is more about deployment, and also because later will see how to persist data
on production by using AWS volumes, let's just leave it like that.

Keep in mind that for a daily development workflow, you **want** to mount your source
file into the application container. That way you can see your changes immediately
inside of the container. You can accomplish this with just one line of code:

    volumes:
      - .:/path-to-my-source

That's going to mount your local source code to the folder where the application
lives inside of the container.

The final `docker-compose.yml` file should look like this:

    version: '2'
    services:
      webapp_setup:
        build: .
        depends_on:
          - postgres
        environment:
          - PASSENGER_APP_ENV=development
        entrypoint: ./setup.sh
      webapp:
        build: .
        depends_on:
          - postgres
          - webapp_setup
        environment:
          - PASSENGER_APP_ENV=development
        ports:
          - "80:80"
      postgres:
        image: postgres:9.5.3
        environment:
          - POSTGRES_PASSWORD=mysecretpassword
          - POSTGRES_USER=articles

### Build and Run

Let's run a Docker Compose build first for building our web application and
setup containers:

    $ docker-compose build

Output:

    postgres uses an image, skipping
    Building webapp_setup
    Step 1 : FROM phusion/passenger-ruby23:0.9.19
    f069f1d21059: Pull complete
    ecbeec5633cf: Pull complete
    ea6f18256d63: Pull complete
    54bde7b02897: Pull complete
    a3ed95caeb02: Pull complete
    ce9e695a6234: Pull complete
    346026b9659b: Extracting [=============================================>     ] 29.16 MB/32.19 MB
    ffaf5356e027: Download complete
    85417a8aee4f: Downloading [===============>                                   ] 45.33 MB/147.5 MB
    ...
    (truncated)

The first time you run this command it may take some time, since the Docker engine has
to pull the image, install the dependencies and install the gems. At the end
you should see something like this in the output:

    (truncated)
    Step 16 : RUN chown -R app:app /home/app/webapp
     ---> Using cache
     ---> 54deb341aead
    Step 17 : WORKDIR /home/app/webapp
     ---> Using cache
     ---> 1ed66ec118c5
    Step 18 : RUN apt-get clean && rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/*
     ---> Using cache
     ---> ac2951626316
    Step 19 : EXPOSE 80
     ---> Using cache
     ---> 47e8a4833c88
    Successfully built 47e8a4833c88

Meaning that the web application image was successfully built.
Now we can run the Docker Compose up command to pull the PostgreSQL image,
run the initialization script and setup the entire system:

    $ docker-compose up

Some interesting parts you can see in the output are:


    Pulling postgres (postgres:9.5.3)...
    5c90d4a2d1a8: Extracting [=================================================> ] 50.86 MB/51.35 MB
    5c90d4a2d1a8: Downloading [===========================>                       ] 28.25 MB/51.35 MBd complete
    c3961b297acc: Download complete
    ...

For the PostgreSQL image pull,

    postgres_1      | server started
    postgres_1      | CREATE DATABASE
    postgres_1      |
    postgres_1      | CREATE ROLE
    postgres_1      |
    postgres_1      |
    postgres_1      | /docker-entrypoint.sh: ignoring /docker-entrypoint-initdb.d/*
    postgres_1      |
    postgres_1      | LOG:  received fast shutdown request
    postgres_1      | LOG:  aborting any active transactions
    postgres_1      | waiting for server to shut down....LOG:  autovacuum launcher shutting down
    postgres_1      | LOG:  shutting down
    postgres_1      | LOG:  database system is shut down
    webapp_setup_1  | Waiting PostgreSQL to start on 5432...
    postgres_1      |  done
    postgres_1      | server stopped
    postgres_1      |
    postgres_1      | PostgreSQL init process complete; ready for start up.
    postgres_1      |
    postgres_1      | LOG:  database system was shut down at 2016-07-23 21:59:34 UTC
    postgres_1      | LOG:  MultiXact member wraparound protections are now enabled
    postgres_1      | LOG:  database system is ready to accept connections
    postgres_1      | LOG:  autovacuum launcher started
    webapp_setup_1  | PostgreSQL started
    postgres_1      | LOG:  incomplete startup packet
    webapp_setup_1  | == 20160723153218 CreateArticles: migrating ===================================
    webapp_setup_1  | -- create_table(:articles)
    webapp_setup_1  |    -> 0.0095s
    webapp_setup_1  | == 20160723153218 CreateArticles: migrated (0.0096s) ==========================
    webapp_setup_1  |
    articles_webapp_setup_1 exited with code 0

And here in my case you can see our script in action. If you look at the line that says:

    webapp_setup_1  | Waiting PostgreSQL to start on 5432...

You can see the setup container trying to connect to the PostgreSQL container
in order to run the migrations, but the PostgreSQL initialization wasn't ready yet.

Then you see our `PostgreSQL started` message almost at the end and then the database migration being executed.
You can also see the setup container being exited.

Finally you'll see something like this:

    webapp_1        | [ 2016-07-23 21:59:34.0235 29/7fcb59860780 age/Wat/WatchdogMain.cpp:1291 ]: Starting Passenger watchdog...
    webapp_1        | [ 2016-07-23 21:59:34.0414 32/7f7300922780 age/Cor/CoreMain.cpp:982 ]: Starting Passenger core...
    webapp_1        | [ 2016-07-23 21:59:34.0415 32/7f7300922780 age/Cor/CoreMain.cpp:235 ]: Passenger core running in multi-application mode.
    webapp_1        | [ 2016-07-23 21:59:34.0433 32/7f7300922780 age/Cor/CoreMain.cpp:732 ]: Passenger core online, PID 32
    webapp_1        | [ 2016-07-23 21:59:34.0666 41/7f3ed7fe5780 age/Ust/UstRouterMain.cpp:529 ]: Starting Passenger UstRouter...
    webapp_1        | [ 2016-07-23 21:59:34.0676 41/7f3ed7fe5780 age/Ust/UstRouterMain.cpp:342 ]: Passenger UstRouter online, PID 41

Which indicates that the passenger and Nginx processes are ready and listening.

Let's test the application via cURL. You should replace the localhost address
with whatever you're using for running Docker. In my case I'm using Docker for Mac,
so my Docker IP is localhost. Also remember not to kill the Docker Compose up process.

Open a different tab and test the create endpoint:

    $ curl -H "Content-Type: application/json" -X POST -d '{"title":"my first article","body":"Lorem ipsum dolor sit amet, consectetur adipiscing elit..."}' http://localhost/articles

Output:

    {"id":1,"title":"my first article","body":"Lorem ipsum dolor sit amet, consectetur adipiscing elit...","created_at":"2016-07-23T22:06:59.882Z","update...

Awesome! That means our application is up and running. I can go and visit `http://localhost/articles`
and see the article we just created.

## Pushing the app to DockerHub

In order to be able to run our web application with Kubernetes, we need to push
our image to some registry. Let's use a public repository from DockerHub and
later I'll show how you can use a private one.

First, make sure you are logged in with your Docker account by running:

    $ docker login

That's going to ask you for your DockerHub credentials. Now go to `https://hub.docker.com/`
and create a new public repository and name it `articles`.

Now, let's build an initial version of our application. Replace `username` with yours:


    $ docker build -t username/articles:v_0 .

And now push it to your remote repository:

    $ docker push username/articles:v_0

Now we can start writing the Kubernetes templates for deploying our application.

## Adding a resource

We said this was going to be an API for managing articles, so let's create
a simple article resource:

    $ rails g scaffold articles title:string body:text

This scaffold is actually pretty cool because it detects that our application
is api-only, so it generates a controller already adapted for
JSON responses.

Let's migrate the database:

    $ rake db:migrate

And now run the tests:

    $ rake

Output:

    Run options: --seed 3922

    # Running:

    .....

    Finished in 0.518557s, 9.6421 runs/s, 13.4990 assertions/s.

    5 runs, 7 assertions, 0 failures, 0 errors, 0 skips

If we want to test a couple of endpoints, we can always use cURL for
interacting with the API. First, we have to make sure the server is running:

    $ rails s

And then if we want to create an article we can use something like:

    $ curl -H "Content-Type: application/json" -X POST -d '{"title":"my first article","body":"Lorem ipsum dolor sit amet, consectetur adipiscing elit..."}' http://localhost:3000/articles

Output:

    {"id":1,"title":"my first article","body":"Lorem ipsum dolor sit amet, consectetur adipiscing elit...","created_at":"2016-07-23T15:40:53.352Z"

That means the article was indeed created in our database. Just in case you don't
believe me:

    $ rails c
    > Article.first
    => #<Article id: 1, title: "my first article", body: "Lorem ipsum dolor sit amet, consectetur adipiscing...", created_at: "2016-07-23 15:40:53", updated_at: "2016-07-23 15:40:53">

Cool. Now that we have our API pretty much ready, it's time to dockerize the application.
